{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face detection using Amazon Rekognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "This notebook provides a walkthrough of [face detection API](https://docs.aws.amazon.com/rekognition/latest/dg/faces.html) in Amazon Rekognition to identify faces.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize dependencies\n",
    "import boto3\n",
    "import botocore\n",
    "from IPython.display import HTML, display, Image as IImage\n",
    "import time\n",
    "\n",
    "# Initialize clients\n",
    "REGION = boto3.session.Session().region_name\n",
    "rekognition = boto3.client('rekognition', REGION)\n",
    "s3 = boto3.client('s3', REGION)\n",
    "\n",
    "%store -r bucket_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect faces in image\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://amazon-rekognition-code-samples-678987013791-us-east-1.s3.amazonaws.com/media/looking_at_screen.jpg?AWSAccessKeyId=ASIAZ4FWHT2PW7VTFIWH&Signature=bC89x%2FeZ2oFSKFUg2WM%2BIQQzCu8%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEG0aCXVzLWVhc3QtMSJGMEQCIBGowoF3Pt4ziG7Z%2F8yGOyn0xXj3%2BuP1yFrwxvZyEN2sAiBcbIdk9qwP1Ee6GGtpNI73z5OZcAtlTTqTF3yPkfxXOir%2BAgjF%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F8BEAEaDDY3ODk4NzAxMzc5MSIMSv%2BA6ntFDIQ05Wo9KtICzQnMjvffuSbZhZNgJ5AB7%2BfVb1ugdVHxc7S3Q%2FJopmFpl%2BfFTPaY1JNIvNoP7uYKG2r0aabNbUXZBIhlZP9kqLaPLNBNxKeH6ot%2FQTqK5lNS08uLSRz3NEGAg2WfYDSAfAKM7c5Q9DwbmcacK6iNgzLgcdUwBYultPGThzhHHuAWDBLuYBxZY85fFL6j%2FN7LlL1bsdH1kaaYdnjijYaR92RMVqun8CgExxDrn5Agau0IPX4kvzgkB17sLQVAAemMa%2BOr12xCEVT1V1bNCkwKRsMXMkfqY8%2F7ZR7Q2oQ1jyuqrd7QihqFwvMeATDw%2FbnoPYQoN0jWDuqNKzY%2BIIgGCzt1UWd3nxtRKQMSch8f5yaCthythoK0Bry%2B9chnixVmHqolz29BL2AqNxduMoNfsfFKdoMqea2%2B3EJKiw3xxyT%2BsMlau7chJOIKuzPhwF3O1kww6NLSgwY6xAF832WHb%2BTiiKAy%2FEB%2F8A%2FR0gU67EwQ70mLX3oqRBgkZ0puRPetFpI%2BpfqFzeTL08%2FgkLFEuthDOS0PfK6V5zYAlz2W30c2y0G0QPKo1GzxSdxE5slP2SSbWV3Hk3GhBIeSAKZe%2FAHcfdiAE2Po8AqmaJo9p6vlQ6xdKwRcAgtijjEADYNSViCQFyz%2F1IH1MbU3JRvRVZmoB168j83%2Fz%2Br5qSPsV%2Fz8tbU%2FIBFFYmOMGyCYyUylNmb4dMyNaB1EmmZaffyD&Expires=1618262982\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show image\n",
    "image_name = \"media/looking_at_screen.jpg\"\n",
    "display(IImage(url=s3.generate_presigned_url('get_object', Params={'Bucket': bucket_name, 'Key': image_name})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call Rekognition to detect faces in the image\n",
    "\n",
    "<https://docs.aws.amazon.com/rekognition/latest/dg/API_DetectFaces.html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_faces_response = rekognition.detect_faces(\n",
    "    Attributes=['ALL'],\n",
    "    Image={\n",
    "        'S3Object': {\n",
    "            'Bucket': bucket_name,\n",
    "            'Name': image_name,\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Review the raw JSON reponse from Rekognition\n",
    "\n",
    "In the JSON response below, you will see faces, detected attributes, confidence score and additional information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FaceDetails': [{'BoundingBox': {'Width': 0.1504521667957306,\n",
       "    'Height': 0.38279294967651367,\n",
       "    'Left': 0.44695040583610535,\n",
       "    'Top': 0.20570430159568787},\n",
       "   'AgeRange': {'Low': 28, 'High': 44},\n",
       "   'Smile': {'Value': False, 'Confidence': 99.86727905273438},\n",
       "   'Eyeglasses': {'Value': False, 'Confidence': 83.88892364501953},\n",
       "   'Sunglasses': {'Value': False, 'Confidence': 96.896728515625},\n",
       "   'Gender': {'Value': 'Male', 'Confidence': 99.84075164794922},\n",
       "   'Beard': {'Value': True, 'Confidence': 88.31685638427734},\n",
       "   'Mustache': {'Value': False, 'Confidence': 84.35069274902344},\n",
       "   'EyesOpen': {'Value': True, 'Confidence': 97.81980895996094},\n",
       "   'MouthOpen': {'Value': False, 'Confidence': 97.85012817382812},\n",
       "   'Emotions': [{'Type': 'CALM', 'Confidence': 88.19454193115234},\n",
       "    {'Type': 'SAD', 'Confidence': 11.324813842773438},\n",
       "    {'Type': 'CONFUSED', 'Confidence': 0.3489232659339905},\n",
       "    {'Type': 'ANGRY', 'Confidence': 0.06281154602766037},\n",
       "    {'Type': 'FEAR', 'Confidence': 0.03483998775482178},\n",
       "    {'Type': 'SURPRISED', 'Confidence': 0.019494356587529182},\n",
       "    {'Type': 'HAPPY', 'Confidence': 0.009815390221774578},\n",
       "    {'Type': 'DISGUSTED', 'Confidence': 0.0047581372782588005}],\n",
       "   'Landmarks': [{'Type': 'eyeLeft',\n",
       "     'X': 0.4900754392147064,\n",
       "     'Y': 0.3593207895755768},\n",
       "    {'Type': 'eyeRight', 'X': 0.5561590194702148, 'Y': 0.3529607951641083},\n",
       "    {'Type': 'mouthLeft', 'X': 0.49858930706977844, 'Y': 0.48491787910461426},\n",
       "    {'Type': 'mouthRight', 'X': 0.5535256862640381, 'Y': 0.47967541217803955},\n",
       "    {'Type': 'nose', 'X': 0.5233169198036194, 'Y': 0.41277310252189636},\n",
       "    {'Type': 'leftEyeBrowLeft',\n",
       "     'X': 0.46483084559440613,\n",
       "     'Y': 0.33587849140167236},\n",
       "    {'Type': 'leftEyeBrowRight',\n",
       "     'X': 0.4831000566482544,\n",
       "     'Y': 0.31366726756095886},\n",
       "    {'Type': 'leftEyeBrowUp',\n",
       "     'X': 0.5022429823875427,\n",
       "     'Y': 0.3165312111377716},\n",
       "    {'Type': 'rightEyeBrowLeft',\n",
       "     'X': 0.5401809811592102,\n",
       "     'Y': 0.3128795027732849},\n",
       "    {'Type': 'rightEyeBrowRight',\n",
       "     'X': 0.5594688057899475,\n",
       "     'Y': 0.3063219487667084},\n",
       "    {'Type': 'rightEyeBrowUp',\n",
       "     'X': 0.5798178911209106,\n",
       "     'Y': 0.32477062940597534},\n",
       "    {'Type': 'leftEyeLeft', 'X': 0.4783575236797333, 'Y': 0.361129492521286},\n",
       "    {'Type': 'leftEyeRight',\n",
       "     'X': 0.5030425786972046,\n",
       "     'Y': 0.35916247963905334},\n",
       "    {'Type': 'leftEyeUp', 'X': 0.4895721673965454, 'Y': 0.35235992074012756},\n",
       "    {'Type': 'leftEyeDown',\n",
       "     'X': 0.49039921164512634,\n",
       "     'Y': 0.36471349000930786},\n",
       "    {'Type': 'rightEyeLeft',\n",
       "     'X': 0.5429673790931702,\n",
       "     'Y': 0.35532090067863464},\n",
       "    {'Type': 'rightEyeRight',\n",
       "     'X': 0.5678996443748474,\n",
       "     'Y': 0.35253065824508667},\n",
       "    {'Type': 'rightEyeUp', 'X': 0.5559445023536682, 'Y': 0.3459779918193817},\n",
       "    {'Type': 'rightEyeDown', 'X': 0.5558278560638428, 'Y': 0.3584299087524414},\n",
       "    {'Type': 'noseLeft', 'X': 0.5118677616119385, 'Y': 0.43408018350601196},\n",
       "    {'Type': 'noseRight', 'X': 0.5363230109214783, 'Y': 0.43176594376564026},\n",
       "    {'Type': 'mouthUp', 'X': 0.5247291326522827, 'Y': 0.4619429111480713},\n",
       "    {'Type': 'mouthDown', 'X': 0.5258028507232666, 'Y': 0.5013114809989929},\n",
       "    {'Type': 'leftPupil', 'X': 0.4900754392147064, 'Y': 0.3593207895755768},\n",
       "    {'Type': 'rightPupil', 'X': 0.5561590194702148, 'Y': 0.3529607951641083},\n",
       "    {'Type': 'upperJawlineLeft',\n",
       "     'X': 0.4522995948791504,\n",
       "     'Y': 0.38080576062202454},\n",
       "    {'Type': 'midJawlineLeft',\n",
       "     'X': 0.4691944718360901,\n",
       "     'Y': 0.513750433921814},\n",
       "    {'Type': 'chinBottom', 'X': 0.5280338525772095, 'Y': 0.571112334728241},\n",
       "    {'Type': 'midJawlineRight',\n",
       "     'X': 0.5863138437271118,\n",
       "     'Y': 0.5025706887245178},\n",
       "    {'Type': 'upperJawlineRight',\n",
       "     'X': 0.5966976881027222,\n",
       "     'Y': 0.3668808043003082}],\n",
       "   'Pose': {'Roll': -3.802114963531494,\n",
       "    'Yaw': 0.21718214452266693,\n",
       "    'Pitch': 13.59980297088623},\n",
       "   'Quality': {'Brightness': 64.3919677734375, 'Sharpness': 78.64350128173828},\n",
       "   'Confidence': 99.99974060058594}],\n",
       " 'ResponseMetadata': {'RequestId': '5217fc2a-05a2-43ba-bb91-922052434486',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'content-type': 'application/x-amz-json-1.1',\n",
       "   'date': 'Mon, 12 Apr 2021 20:29:46 GMT',\n",
       "   'x-amzn-requestid': '5217fc2a-05a2-43ba-bb91-922052434486',\n",
       "   'content-length': '3355',\n",
       "   'connection': 'keep-alive'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(detect_faces_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display number of faces detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of faces detected: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of faces detected: {}\".format(len(detect_faces_response['FaceDetails'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recognize faces in video\n",
    "Face recognition in video is an async operation. \n",
    "https://docs.aws.amazon.com/rekognition/latest/dg/API_StartFaceDetection.html. \n",
    "\n",
    "- First we start a face detection job which returns a Job Id.\n",
    "- We can then call `get_face_detection` to get the job status and after job is complete, we can get object metadata.\n",
    "- In production use cases, you would usually use StepFunction or SNS topic to get notified when job is complete.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show video in the player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td style='vertical-align: top'><video controls='controls' autoplay width='640' height='360' name='Video' src='https://amazon-rekognition-code-samples-678987013791-us-east-1.s3.amazonaws.com/media/leaving.mp4?AWSAccessKeyId=ASIAZ4FWHT2PW7VTFIWH&Signature=mEO0H%2FLjjv2z7L7C2Ql8NFajY%2F8%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEG0aCXVzLWVhc3QtMSJGMEQCIBGowoF3Pt4ziG7Z%2F8yGOyn0xXj3%2BuP1yFrwxvZyEN2sAiBcbIdk9qwP1Ee6GGtpNI73z5OZcAtlTTqTF3yPkfxXOir%2BAgjF%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F8BEAEaDDY3ODk4NzAxMzc5MSIMSv%2BA6ntFDIQ05Wo9KtICzQnMjvffuSbZhZNgJ5AB7%2BfVb1ugdVHxc7S3Q%2FJopmFpl%2BfFTPaY1JNIvNoP7uYKG2r0aabNbUXZBIhlZP9kqLaPLNBNxKeH6ot%2FQTqK5lNS08uLSRz3NEGAg2WfYDSAfAKM7c5Q9DwbmcacK6iNgzLgcdUwBYultPGThzhHHuAWDBLuYBxZY85fFL6j%2FN7LlL1bsdH1kaaYdnjijYaR92RMVqun8CgExxDrn5Agau0IPX4kvzgkB17sLQVAAemMa%2BOr12xCEVT1V1bNCkwKRsMXMkfqY8%2F7ZR7Q2oQ1jyuqrd7QihqFwvMeATDw%2FbnoPYQoN0jWDuqNKzY%2BIIgGCzt1UWd3nxtRKQMSch8f5yaCthythoK0Bry%2B9chnixVmHqolz29BL2AqNxduMoNfsfFKdoMqea2%2B3EJKiw3xxyT%2BsMlau7chJOIKuzPhwF3O1kww6NLSgwY6xAF832WHb%2BTiiKAy%2FEB%2F8A%2FR0gU67EwQ70mLX3oqRBgkZ0puRPetFpI%2BpfqFzeTL08%2FgkLFEuthDOS0PfK6V5zYAlz2W30c2y0G0QPKo1GzxSdxE5slP2SSbWV3Hk3GhBIeSAKZe%2FAHcfdiAE2Po8AqmaJo9p6vlQ6xdKwRcAgtijjEADYNSViCQFyz%2F1IH1MbU3JRvRVZmoB168j83%2Fz%2Br5qSPsV%2Fz8tbU%2FIBFFYmOMGyCYyUylNmb4dMyNaB1EmmZaffyD&Expires=1618263021'></video></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "video_name = \"media/leaving.mp4\"\n",
    "s3_video_url = s3.generate_presigned_url('get_object', Params={'Bucket': bucket_name, 'Key': video_name})\n",
    "\n",
    "video_tag = \"<video controls='controls' autoplay width='640' height='360' name='Video' src='{0}'></video>\".format(s3_video_url)\n",
    "video_ui = \"<table><tr><td style='vertical-align: top'>{}</td></tr></table>\".format(video_tag)\n",
    "display(HTML(video_ui))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call Rekognition to start a job for face detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Job Id: 676f09bdc9cb3f3175f14e0151a4d2aa94370327107cfa4fade9c44adc24b81d'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_face_detection = rekognition.start_face_detection(\n",
    "    Video={\n",
    "        'S3Object': {\n",
    "            'Bucket': bucket_name,\n",
    "            'Name': video_name,\n",
    "        }\n",
    "    },\n",
    ")\n",
    "\n",
    "faces_job_id = start_face_detection['JobId']\n",
    "display(\"Job Id: {0}\".format(faces_job_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional (Optional) Request Attributes\n",
    "\n",
    "ClientRequestToken:\n",
    "https://docs.aws.amazon.com/rekognition/latest/dg/API_StartFaceDetection.html#rekognition-StartFaceDetection-request-ClientRequestToken\n",
    "\n",
    "FaceAttributes:\n",
    "https://docs.aws.amazon.com/rekognition/latest/dg/API_StartFaceDetection.html#rekognition-StartFaceDetection-request-FaceAttributes\n",
    "\n",
    "JobTag:\n",
    "https://docs.aws.amazon.com/rekognition/latest/dg/API_StartFaceDetection.html#rekognition-StartFaceDetection-request-JobTag\n",
    "\n",
    "NotificationChannel:\n",
    "https://docs.aws.amazon.com/rekognition/latest/dg/API_StartFaceDetection.html#rekognition-StartFaceDetection-request-NotificationChannel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wait for object detection job to complete\n",
    "\n",
    "In production use cases, you would usually use StepFunction or SNS topic to get notified when job is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....."
     ]
    },
    {
     "data": {
      "text/plain": [
       "'SUCCEEDED'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_face_detection = rekognition.get_face_detection(\n",
    "    JobId=faces_job_id\n",
    ")\n",
    "\n",
    "while(get_face_detection['JobStatus'] == 'IN_PROGRESS'):\n",
    "    time.sleep(5)\n",
    "    print('.', end='')\n",
    " \n",
    "    get_face_detection = rekognition.get_face_detection(\n",
    "        JobId=faces_job_id)\n",
    "    \n",
    "display(get_face_detection['JobStatus'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Review raw JSON reponse from Rekognition\n",
    "\n",
    "In the JSON response below, you will see list of detected faces and attributes.\n",
    "For each detected face, you will see information like Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'JobStatus': 'SUCCEEDED',\n",
       " 'VideoMetadata': {'Codec': 'h264',\n",
       "  'DurationMillis': 8275,\n",
       "  'Format': 'QuickTime / MOV',\n",
       "  'FrameRate': 29.970029830932617,\n",
       "  'FrameHeight': 720,\n",
       "  'FrameWidth': 1280},\n",
       " 'Faces': [{'Timestamp': 0,\n",
       "   'Face': {'BoundingBox': {'Width': 0.16494020819664001,\n",
       "     'Height': 0.40895530581474304,\n",
       "     'Left': 0.4051298201084137,\n",
       "     'Top': 0.19038063287734985},\n",
       "    'Landmarks': [{'Type': 'eyeLeft',\n",
       "      'X': 0.4491073191165924,\n",
       "      'Y': 0.3539910614490509},\n",
       "     {'Type': 'eyeRight', 'X': 0.5216923356056213, 'Y': 0.34899502992630005},\n",
       "     {'Type': 'mouthLeft', 'X': 0.4577264189720154, 'Y': 0.49589675664901733},\n",
       "     {'Type': 'mouthRight', 'X': 0.517991304397583, 'Y': 0.49166396260261536},\n",
       "     {'Type': 'nose', 'X': 0.48547428846359253, 'Y': 0.4145564138889313}],\n",
       "    'Pose': {'Roll': -3.1053874492645264,\n",
       "     'Yaw': -1.0365235805511475,\n",
       "     'Pitch': 12.688544273376465},\n",
       "    'Quality': {'Brightness': 61.28426742553711,\n",
       "     'Sharpness': 67.22731018066406},\n",
       "    'Confidence': 99.99785614013672}},\n",
       "  {'Timestamp': 467,\n",
       "   'Face': {'BoundingBox': {'Width': 0.16470026969909668,\n",
       "     'Height': 0.4098578691482544,\n",
       "     'Left': 0.4053584635257721,\n",
       "     'Top': 0.19019187986850739},\n",
       "    'Landmarks': [{'Type': 'eyeLeft',\n",
       "      'X': 0.4494580328464508,\n",
       "      'Y': 0.35415416955947876},\n",
       "     {'Type': 'eyeRight', 'X': 0.5221157073974609, 'Y': 0.34921056032180786},\n",
       "     {'Type': 'mouthLeft', 'X': 0.45815205574035645, 'Y': 0.4960460662841797},\n",
       "     {'Type': 'mouthRight', 'X': 0.5184893012046814, 'Y': 0.4918859601020813},\n",
       "     {'Type': 'nose', 'X': 0.4855023920536041, 'Y': 0.41496777534484863}],\n",
       "    'Pose': {'Roll': -3.273860454559326,\n",
       "     'Yaw': -1.0868194103240967,\n",
       "     'Pitch': 13.101612091064453},\n",
       "    'Quality': {'Brightness': 61.452178955078125,\n",
       "     'Sharpness': 67.22731018066406},\n",
       "    'Confidence': 99.9980697631836}},\n",
       "  {'Timestamp': 967,\n",
       "   'Face': {'BoundingBox': {'Width': 0.16478300094604492,\n",
       "     'Height': 0.4138263165950775,\n",
       "     'Left': 0.4078032076358795,\n",
       "     'Top': 0.18654993176460266},\n",
       "    'Landmarks': [{'Type': 'eyeLeft',\n",
       "      'X': 0.45061054825782776,\n",
       "      'Y': 0.34855571389198303},\n",
       "     {'Type': 'eyeRight', 'X': 0.5231393575668335, 'Y': 0.34269559383392334},\n",
       "     {'Type': 'mouthLeft', 'X': 0.4599624276161194, 'Y': 0.4892749786376953},\n",
       "     {'Type': 'mouthRight', 'X': 0.5201968550682068, 'Y': 0.484350323677063},\n",
       "     {'Type': 'nose', 'X': 0.48734530806541443, 'Y': 0.40713563561439514}],\n",
       "    'Pose': {'Roll': -3.2429862022399902,\n",
       "     'Yaw': -1.091920256614685,\n",
       "     'Pitch': 13.203895568847656},\n",
       "    'Quality': {'Brightness': 61.97950744628906,\n",
       "     'Sharpness': 67.22731018066406},\n",
       "    'Confidence': 99.99800872802734}},\n",
       "  {'Timestamp': 1468,\n",
       "   'Face': {'BoundingBox': {'Width': 0.17112097144126892,\n",
       "     'Height': 0.42207005620002747,\n",
       "     'Left': 0.4135075509548187,\n",
       "     'Top': 0.17380750179290771},\n",
       "    'Landmarks': [{'Type': 'eyeLeft',\n",
       "      'X': 0.4621911644935608,\n",
       "      'Y': 0.34342527389526367},\n",
       "     {'Type': 'eyeRight', 'X': 0.5365821719169617, 'Y': 0.3387342095375061},\n",
       "     {'Type': 'mouthLeft', 'X': 0.47078737616539, 'Y': 0.49146613478660583},\n",
       "     {'Type': 'mouthRight', 'X': 0.5325114727020264, 'Y': 0.4874652326107025},\n",
       "     {'Type': 'nose', 'X': 0.4999724328517914, 'Y': 0.40523919463157654}],\n",
       "    'Pose': {'Roll': -2.5615901947021484,\n",
       "     'Yaw': -0.41531872749328613,\n",
       "     'Pitch': 13.326993942260742},\n",
       "    'Quality': {'Brightness': 62.89448547363281,\n",
       "     'Sharpness': 73.32209777832031},\n",
       "    'Confidence': 99.99864959716797}},\n",
       "  {'Timestamp': 1968,\n",
       "   'Face': {'BoundingBox': {'Width': 0.23280653357505798,\n",
       "     'Height': 0.43232348561286926,\n",
       "     'Left': 0.40760746598243713,\n",
       "     'Top': -0.013983742333948612},\n",
       "    'Landmarks': [{'Type': 'eyeLeft',\n",
       "      'X': 0.48416513204574585,\n",
       "      'Y': 0.015593336895108223},\n",
       "     {'Type': 'eyeRight', 'X': 0.5758888721466064, 'Y': 0.00586892431601882},\n",
       "     {'Type': 'mouthLeft', 'X': 0.4981380105018616, 'Y': 0.25107577443122864},\n",
       "     {'Type': 'mouthRight', 'X': 0.5744746923446655, 'Y': 0.2427833378314972},\n",
       "     {'Type': 'nose', 'X': 0.5348861217498779, 'Y': 0.10690423101186752}],\n",
       "    'Pose': {'Roll': -2.07012939453125,\n",
       "     'Yaw': 2.253540277481079,\n",
       "     'Pitch': 8.21743106842041},\n",
       "    'Quality': {'Brightness': 54.72004318237305,\n",
       "     'Sharpness': 20.927310943603516},\n",
       "    'Confidence': 99.98971557617188}},\n",
       "  {'Timestamp': 7474,\n",
       "   'Face': {'BoundingBox': {'Width': 0.26162537932395935,\n",
       "     'Height': 0.5017482042312622,\n",
       "     'Left': 0.3827286660671234,\n",
       "     'Top': -0.00603836914524436},\n",
       "    'Landmarks': [{'Type': 'eyeLeft',\n",
       "      'X': 0.45888954401016235,\n",
       "      'Y': 0.03203366696834564},\n",
       "     {'Type': 'eyeRight', 'X': 0.5639471411705017, 'Y': 0.024723153561353683},\n",
       "     {'Type': 'mouthLeft', 'X': 0.47140806913375854, 'Y': 0.30126091837882996},\n",
       "     {'Type': 'mouthRight', 'X': 0.5591217875480652, 'Y': 0.2949972450733185},\n",
       "     {'Type': 'nose', 'X': 0.5114954710006714, 'Y': 0.14806951582431793}],\n",
       "    'Pose': {'Roll': 0.5334663987159729,\n",
       "     'Yaw': -1.15448796749115,\n",
       "     'Pitch': -6.2242021560668945},\n",
       "    'Quality': {'Brightness': 63.033103942871094,\n",
       "     'Sharpness': 20.927310943603516},\n",
       "    'Confidence': 99.98461151123047}},\n",
       "  {'Timestamp': 7974,\n",
       "   'Face': {'BoundingBox': {'Width': 0.16075916588306427,\n",
       "     'Height': 0.3951421082019806,\n",
       "     'Left': 0.4008542597293854,\n",
       "     'Top': 0.25242406129837036},\n",
       "    'Landmarks': [{'Type': 'eyeLeft',\n",
       "      'X': 0.4460684359073639,\n",
       "      'Y': 0.4066290259361267},\n",
       "     {'Type': 'eyeRight', 'X': 0.5186374187469482, 'Y': 0.40395286679267883},\n",
       "     {'Type': 'mouthLeft', 'X': 0.4537857472896576, 'Y': 0.5447381138801575},\n",
       "     {'Type': 'mouthRight', 'X': 0.5141162872314453, 'Y': 0.5424709916114807},\n",
       "     {'Type': 'nose', 'X': 0.4832732081413269, 'Y': 0.46648940443992615}],\n",
       "    'Pose': {'Roll': -1.8191187381744385,\n",
       "     'Yaw': 0.34263908863067627,\n",
       "     'Pitch': 13.76653003692627},\n",
       "    'Quality': {'Brightness': 61.182167053222656,\n",
       "     'Sharpness': 60.49041748046875},\n",
       "    'Confidence': 99.99800872802734}}],\n",
       " 'ResponseMetadata': {'RequestId': '00c85d7f-0e08-46de-9f98-0e8684f86451',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'content-type': 'application/x-amz-json-1.1',\n",
       "   'date': 'Mon, 12 Apr 2021 20:30:59 GMT',\n",
       "   'x-amzn-requestid': '00c85d7f-0e08-46de-9f98-0e8684f86451',\n",
       "   'content-length': '5016',\n",
       "   'connection': 'keep-alive'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(get_face_detection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display face detected by timestamp and alert when faces are not detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected face on Timestamp: 0 with confidence: 99.99785614013672\n",
      "Detected face on Timestamp: 467 with confidence: 99.9980697631836\n",
      "Detected face on Timestamp: 967 with confidence: 99.99800872802734\n",
      "Detected face on Timestamp: 1468 with confidence: 99.99864959716797\n",
      "Detected face on Timestamp: 1968 with confidence: 99.98971557617188\n",
      "ALERT - no face detected for 5.506 seconds\n",
      "Detected face on Timestamp: 7474 with confidence: 99.98461151123047\n",
      "Detected face on Timestamp: 7974 with confidence: 99.99800872802734\n"
     ]
    }
   ],
   "source": [
    "# Faces detected in each frame\n",
    "prev_ts = 0\n",
    "threshold = 1000 # ms\n",
    "for face in get_face_detection['Faces']:\n",
    "    ts = face[\"Timestamp\"]\n",
    "    cconfidence = face[\"Face\"][\"Confidence\"]\n",
    "    if ts-prev_ts>threshold:\n",
    "        print(\"ALERT - no face detected for {} seconds\".format((ts-prev_ts)/1000))\n",
    "    print(\"Detected face on Timestamp: {} with confidence: {}\".format(ts, cconfidence))\n",
    "    prev_ts = ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### References\n",
    "- https://docs.aws.amazon.com/rekognition/latest/dg/API_DetectFaces.html\n",
    "- https://docs.aws.amazon.com/rekognition/latest/dg/API_StartFaceDetection.html\n",
    "- https://docs.aws.amazon.com/rekognition/latest/dg/API_GetFaceDetection.html\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have successfully used Amazon Rekognition to detect faces in images and videos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_mxnet_p36",
   "language": "python",
   "name": "conda_amazonei_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
